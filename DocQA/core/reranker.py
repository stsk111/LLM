"""
DocQA Pro - é‡æ’æ¨¡å—
BGE-Rerankeræ¨¡å‹å°è£…ï¼Œå¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åº
"""

from typing import List, Tuple, Dict, Any
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from langchain_core.documents import Document

from config import RERANKER_MODEL_PATH, RERANKER_DEVICE, RERANKER_BATCH_SIZE


class BGEReranker:
    """BGE Rerankeræ¨¡å‹å°è£…"""
    
    def __init__(self, model_path: str = str(RERANKER_MODEL_PATH)):
        """
        åˆå§‹åŒ–Rerankeræ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
        """
        self.model_path = model_path
        self.device = RERANKER_DEVICE
        self.batch_size = RERANKER_BATCH_SIZE
        
        self.tokenizer = None
        self.model = None
        
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½Rerankeræ¨¡å‹å’Œtokenizer"""
        try:
            print(f"ğŸ”„ åŠ è½½Rerankeræ¨¡å‹: {self.model_path}")
            
            # åŠ è½½tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path,
                trust_remote_code=True
            )
            
            # åŠ è½½æ¨¡å‹
            self.model = AutoModelForSequenceClassification.from_pretrained(
                self.model_path,
                trust_remote_code=True,
                torch_dtype=torch.float16 if self.device == 'cuda' else torch.float32,
                weights_only=False  # æ˜¾å¼å…³é—­ä»…æƒé‡åŠ è½½ï¼Œç»•è¿‡ç‰ˆæœ¬æ£€æŸ¥
            )
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            if torch.cuda.is_available() and self.device == 'cuda':
                self.model = self.model.to(self.device)
            
            self.model.eval()
            print("âœ… Rerankeræ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ Rerankeræ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _compute_scores(self, query: str, texts: List[str]) -> List[float]:
        """
        è®¡ç®—queryä¸æ–‡æœ¬åˆ—è¡¨çš„ç›¸å…³æ€§åˆ†æ•°
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            texts: æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ€§åˆ†æ•°åˆ—è¡¨
        """
        if not self.model or not self.tokenizer:
            raise RuntimeError("Rerankeræ¨¡å‹æœªåŠ è½½")
        
        scores = []
        
        # æ‰¹å¤„ç†è®¡ç®—åˆ†æ•°
        for i in range(0, len(texts), self.batch_size):
            batch_texts = texts[i:i + self.batch_size]
            batch_pairs = [(query, text) for text in batch_texts]
            
            try:
                # Tokenizeè¾“å…¥å¯¹
                inputs = self.tokenizer(
                    batch_pairs,
                    padding=True,
                    truncation=True,
                    return_tensors="pt",
                    max_length=512
                )
                
                # ç§»åŠ¨åˆ°è®¾å¤‡
                if torch.cuda.is_available() and self.device == 'cuda':
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # æ¨ç†
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    batch_scores = outputs.logits.squeeze().cpu().numpy()
                
                # å¤„ç†å•ä¸ªæ ·æœ¬çš„æƒ…å†µ
                if len(batch_texts) == 1:
                    batch_scores = [float(batch_scores)]
                else:
                    batch_scores = batch_scores.tolist()
                
                scores.extend(batch_scores)
                
            except Exception as e:
                print(f"âš ï¸  æ‰¹æ¬¡ {i//self.batch_size + 1} å¤„ç†å¤±è´¥: {e}")
                # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡æ·»åŠ é»˜è®¤åˆ†æ•°
                scores.extend([0.0] * len(batch_texts))
        
        return scores
    
    def rerank(
        self, 
        query: str, 
        documents: List[Document],
        top_n: int = 5,
        score_threshold: float = 0.0
    ) -> List[Tuple[Document, float]]:
        """
        å¯¹æ–‡æ¡£é‡æ–°æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            top_n: è¿”å›å‰Nä¸ªç»“æœ
            score_threshold: åˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤åˆ†æ•°çš„ç»“æœå°†è¢«è¿‡æ»¤
            
        Returns:
            æ’åºåçš„(æ–‡æ¡£, åˆ†æ•°)åˆ—è¡¨
        """
        if not documents:
            return []
        
        try:
            print(f"ğŸ”„ é‡æ’ {len(documents)} ä¸ªæ–‡æ¡£...")
            
            # æå–æ–‡æ¡£æ–‡æœ¬
            texts = [doc.page_content for doc in documents]
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            scores = self._compute_scores(query, texts)
            
            # åˆ›å»º(æ–‡æ¡£, åˆ†æ•°)å¯¹
            doc_score_pairs = list(zip(documents, scores))
            
            # æŒ‰åˆ†æ•°é™åºæ’åº
            doc_score_pairs.sort(key=lambda x: x[1], reverse=True)
            
            # åº”ç”¨åˆ†æ•°é˜ˆå€¼è¿‡æ»¤
            filtered_pairs = [
                (doc, score) for doc, score in doc_score_pairs 
                if score >= score_threshold
            ]
            
            # å–Top-N
            top_results = filtered_pairs[:top_n]
            
            print(f"âœ… é‡æ’å®Œæˆï¼Œè¿”å› {len(top_results)} ä¸ªç»“æœ")
            
            # åœ¨æ–‡æ¡£metadataä¸­æ·»åŠ é‡æ’åˆ†æ•°
            for doc, score in top_results:
                doc.metadata['rerank_score'] = score
            
            return top_results
            
        except Exception as e:
            print(f"âŒ é‡æ’å¤±è´¥: {e}")
            # è¿”å›åŸå§‹æ–‡æ¡£ï¼Œä½†é™åˆ¶æ•°é‡
            return [(doc, 0.0) for doc in documents[:top_n]]
    
    def batch_rerank(
        self,
        queries: List[str],
        document_lists: List[List[Document]],
        top_n: int = 5,
        score_threshold: float = 0.0
    ) -> List[List[Tuple[Document, float]]]:
        """
        æ‰¹é‡é‡æ’å¤šä¸ªæŸ¥è¯¢çš„æ–‡æ¡£
        
        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            document_lists: æ¯ä¸ªæŸ¥è¯¢å¯¹åº”çš„æ–‡æ¡£åˆ—è¡¨
            top_n: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„ç»“æœæ•°
            score_threshold: åˆ†æ•°é˜ˆå€¼
            
        Returns:
            æ¯ä¸ªæŸ¥è¯¢çš„é‡æ’ç»“æœåˆ—è¡¨
        """
        results = []
        
        for query, docs in zip(queries, document_lists):
            reranked = self.rerank(query, docs, top_n, score_threshold)
            results.append(reranked)
        
        return results
    
    def get_relevance_scores(self, query: str, documents: List[Document]) -> Dict[str, float]:
        """
        è·å–æŸ¥è¯¢ä¸æ‰€æœ‰æ–‡æ¡£çš„ç›¸å…³æ€§åˆ†æ•°å­—å…¸
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            æ–‡æ¡£ID -> ç›¸å…³æ€§åˆ†æ•°çš„æ˜ å°„
        """
        if not documents:
            return {}
        
        texts = [doc.page_content for doc in documents]
        scores = self._compute_scores(query, texts)
        
        # åˆ›å»ºæ–‡æ¡£IDåˆ°åˆ†æ•°çš„æ˜ å°„
        score_dict = {}
        for i, (doc, score) in enumerate(zip(documents, scores)):
            # ä½¿ç”¨chunk_idæˆ–è€…ç´¢å¼•ä½œä¸ºkey
            doc_id = doc.metadata.get('chunk_id', f'doc_{i}')
            score_dict[doc_id] = score
        
        return score_dict


def create_reranker(model_path: str = None) -> BGEReranker:
    """
    åˆ›å»ºRerankerå®ä¾‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼Œä¸ºNoneæ—¶ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        
    Returns:
        Rerankerå®ä¾‹
    """
    if model_path is None:
        model_path = str(RERANKER_MODEL_PATH)
    
    return BGEReranker(model_path)