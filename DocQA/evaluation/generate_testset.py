import sys
import os
import dotenv
import pandas as pd
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from ragas.testset.generator import TestsetGenerator
from ragas.testset.evolutions import simple, reasoning, multi_context
from core.ingestion import create_pdf_pipeline
    

dotenv.load_dotenv()
# --- 2. é…ç½®å‚æ•° ---
# è¯·ä¿®æ”¹è¿™é‡Œä¸ºä½ å®é™…æƒ³è¦æµ‹è¯•çš„ PDF æ–‡ä»¶è·¯å¾„
INPUT_PDF_PATH = "dataset/docs/doc.pdf"
OUTPUT_CSV_PATH = "dataset/testset/testset.csv"
TEST_SIZE = 10  # ç”Ÿæˆçš„é—®é¢˜æ•°é‡ï¼Œå»ºè®®å…ˆè®¾ä¸º 10 è¿›è¡Œæµ‹è¯•

def main():
    # --- æ­¥éª¤ A: å¤ç”¨ä½ çš„ ingestion æ¨¡å—åŠ è½½æ–‡æ¡£ ---
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ–‡æ¡£: {INPUT_PDF_PATH}")
    
    if not os.path.exists(INPUT_PDF_PATH):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ -> {INPUT_PDF_PATH}")
        return

    # å®ä¾‹åŒ–ä½ çš„ç®¡é“
    pipeline = create_pdf_pipeline(
        progress_callback=lambda msg, cur, tot: print(f"   [å¤„ç†ä¸­] {msg} ({cur}%)")
    )
    
    # æ‰§è¡Œå¤„ç† (åŒ…å«åŠ è½½ã€éªŒè¯ã€åˆ‡åˆ†)
    result = pipeline.process_pdf(INPUT_PDF_PATH)
    
    if not result["success"]:
        print(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {result.get('error')}")
        return

    # è·å–åˆ‡åˆ†å¥½çš„æ–‡æ¡£å— (chunks)
    # Ragas éœ€è¦è¿™äº› chunks æ¥ç”Ÿæˆç›¸å…³çš„é—®é¢˜
    documents = result["chunks"]
    print(f"âœ… æ–‡æ¡£åŠ è½½æˆåŠŸï¼å…±ç”Ÿæˆ {len(documents)} ä¸ªæ–‡æœ¬å— (Chunk Size: {result['stats']['chunk_size']})")

    # --- æ­¥éª¤ B: åˆå§‹åŒ– Ragas ç”Ÿæˆå™¨ ---
    print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ– Ragas (GPT-4o)...")
    
    # å»ºè®®ä½¿ç”¨ GPT-4o ä»¥è·å¾—æœ€ä½³çš„æ•°æ®ç”Ÿæˆè´¨é‡
    # ç¡®ä¿ç¯å¢ƒå˜é‡ä¸­å·²è®¾ç½® OPENAI_API_KEY
    generator_llm = ChatOpenAI(basemodel="gpt-4o")
    critic_llm = ChatOpenAI(model="gpt-4o")
    embeddings = OpenAIEmbeddings()

    generator = TestsetGenerator.from_langchain(
        generator_llm,
        critic_llm,
        embeddings
    )

    # --- æ­¥éª¤ C: ç”Ÿæˆæµ‹è¯•é›† ---
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆæµ‹è¯•é›† (ç›®æ ‡: {TEST_SIZE} ä¸ªé—®é¢˜)...")
    print("   æç¤º: è¿™éœ€è¦æ¶ˆè€—ä¸€å®šçš„ Token å¹¶èŠ±è´¹å‡ åˆ†é’Ÿæ—¶é—´ã€‚")

    # é™åˆ¶ç”¨äºç”Ÿæˆçš„ chunks æ•°é‡ä»¥èŠ‚çœ Token (å¯é€‰)
    # å¦‚æœ PDF éå¸¸å¤§ï¼Œå»ºè®®åªå–å‰ 20-30 ä¸ª chunk è¿›è¡Œç”Ÿæˆ
    # docs_to_process = documents[:30] 
    docs_to_process = documents 

    try:
        testset = generator.generate_with_langchain_docs(
            docs_to_process,
            test_size=TEST_SIZE,
            distributions={
                simple: 0.5,        # 50% ç®€å•ç›´æ¥æ£€ç´¢é—®é¢˜
                reasoning: 0.25,    # 25% éœ€è¦é€»è¾‘æ¨ç†çš„é—®é¢˜
                multi_context: 0.25 # 25% éœ€è¦ç»¼åˆå¤šæ®µå†…å®¹çš„é—®é¢˜
            },
            raise_exceptions=False # é‡åˆ°ä¸ªåˆ«é”™è¯¯ç»§ç»­æ‰§è¡Œ
        )
    except Exception as e:
        print(f"âŒ Ragas ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return

    # --- æ­¥éª¤ D: ä¿å­˜ç»“æœ ---
    df = testset.to_pandas()
    
    # ç®€å•æ¸…æ´—ï¼šå»é™¤ç”Ÿæˆçš„ NaN è¡Œ
    df = df.dropna(subset=['question', 'ground_truth'])
    
    df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"ğŸ‰ æˆåŠŸï¼æµ‹è¯•æ•°æ®é›†å·²ä¿å­˜è‡³: {OUTPUT_CSV_PATH}")
    print("\næ•°æ®é¢„è§ˆ:")
    print(df[['question', 'ground_truth']].head(3))

if __name__ == "__main__":
    main()